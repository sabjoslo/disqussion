Handles various representations of tokenized natural language data from a collection of files. This includes frequency distributions, probability distributions and a custom Vector representation.

#####Example
```
from core import token_distributions
this_dist=token_distributions(files='244483491/this-qwer.tsv', phrase_model='example_phrase_model')
```

#####Parameters
- `corpus` (str; existing file name): Load an existing corpus of tokens from file. The delimiters recognized as separating tokens in `corpus` are spaces and new lines.
- `files` (str or iterable; existing tsv file name or containing existing tsv file names): Build a corpus using natural language data from `files`.
- `phrase_model` (str; file name): A trained phrase model that can pull n-grams from natural language data in. If unspecified, only uni-grams will be included in the set of tokens returned by `token_distributions().build_corpus`.
- `column` (str; one of `config.COL_KEYS`): If building corpus from natural language data in `files`, pull this data from column `column`. This is **not** the column name, but the column type. (See config.py for customizing the column names associated with column types.)

####token_distributions().set_phrase_model(phrase_model=None)
Set the phrase model used to detect n>1-grams when building the instance&#39;s corpus (see `token_distributions().build_corpus()` below).

#####Example
```
this_dist.set_phrase_model('example_phrase_model')
```

#####Parameters
- `phrase_model` (str; existing file name): A file name containing a phrase model generated by calling `vocabulary.train_phrase_detector()` (see docs on the vocabulary module) or by an instance of [gensim&#39;s Phraser class](https://radimrehurek.com/gensim/models/phrases.html). Defaults to None, which 
means only unigrams will be detected.

####token_distributions().build_corpus()
Build a corpus of tokens from natural language data in `files`.

####token_distributions().save_corpus(fn, add_to_vocab=True)
Save this instance&#39;s corpus to disk so it can be quickly accessed later. The file is saved in plain text, with words separated by a space and sentences separated by a new line. It is by default saved in `VOCAB_DIR` (specified in config.py) and is included in the package&#39;s recognized vocabulary.

#####Example
```
this_dist.save_corpus('244483491/this-qwer-corpus')
```

#####Parameters
- `fn` (str; file name): The name of the file to save the corpus to.
- `add_to_vocab` (bool): If True, `fn` is saved in `VOCAB_DIR` and is visible to the vocabulary module (see docs/vocabulary). Defaults to True.

####token_distributions().load_corpus(fn, from_vocab=True)
Load a saved corpus.

#####Example
```
token_distributions().load_corpus('244483491/this-qwer-corpus')
```

#####Parameters
- `fn` (str; existing file name): File from which to load corpus.
- `from_vocab` (bool): Set to False if `fn` is not stored in VOCAB_DIR. Defaults to True.

####token_distributions().calculate_freq_dist()
Sets this instance&#39;s `freq_dist` attribute to an instance of [nltk&#39;s FreqDist class](http://www.nltk.org/_modules/nltk/probability.html) that represents the frequency distributions of tokens in the instance&#39;s corpus.

####token_distributions().estimate_prob_dist()
Sets this instance&#39;s `prob_dist` attribute to an instance of [nltk&#39;s MLEProbDist class](http://www.nltk.org/_modules/nltk/probability.html) that represents the probability distributions of tokens in the instance&#39;s corpus.

####token_distributions().get_vector(vocab=None)
Sets this instance&#39;s `vector` attribute to an instance of the Vector class representing the probability distributions of the instance&#39;s corpus. `vocab` specifies the set of tokens to include in the Vector&#39;s index. If `vocab` is specified and does not contain a token that appears in the instance&#39;s prob_dist, that token will be excluded from the class&#39;s vector. If unspecified, `vocab` defaults to the samples of the instance&#39;s prob_dist attribute.
